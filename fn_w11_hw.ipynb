{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLhRBn5YGZNE"
      },
      "source": [
        "設計一個多模態模型，採用(a)早期融合、(b)晚期融合或(c)中期融合的方式進行數據整合（擇一實現）。多模態資料來源可包括以下組合之一：\n",
        "    \n",
        "    1. 新聞情緒指標 + 股價資料\n",
        "    2. K 線圖 + 股價資料\n",
        "模型目標可針對分類任務（如股價漲跌預測）或回歸任務（如股價變動幅度預測）。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mplfinance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbOVOzGkZ8k-",
        "outputId": "16c60655-c6f3-4d08-901c-342a695e73d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mplfinance in /usr/local/lib/python3.10/dist-packages (0.12.10b0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mplfinance) (3.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mplfinance) (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mplfinance) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->mplfinance) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mplfinance) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import yfinance as yf\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 設定設備\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 設定股票代號與時間範圍\n",
        "stock_id = '2330.TW'\n",
        "end = dt.date.today()\n",
        "start = end - dt.timedelta(days=3650)\n",
        "df_stat = yf.download(stock_id, start=start, end=end)\n",
        "\n",
        "# 新增移動平均線和其他技術指標\n",
        "df_stat['SMA_5'] = df_stat['Close'].rolling(window=5).mean()\n",
        "df_stat['SMA_20'] = df_stat['Close'].rolling(window=20).mean()\n",
        "df_stat['RSI'] = 100 - (100 / (1 + df_stat['Close'].diff().gt(0).rolling(14).sum() /\n",
        "                                 df_stat['Close'].diff().lt(0).rolling(14).sum()))\n",
        "df_stat = df_stat.dropna()\n",
        "\n",
        "# 添加標籤 (簡單比較 SMA_5 與 SMA_20)\n",
        "df_stat['Label'] = (df_stat['SMA_5'] > df_stat['SMA_20']).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sdVzGYQhABT",
        "outputId": "7e9b117b-2189-4fa3-bc08-cee32e5a71af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 生成 K 線圖並保存\n",
        "def generate_candlestick_images(df, save_dir, window_size=5):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    for i in range(window_size, len(df)):\n",
        "        window_data = df.iloc[i-window_size:i]\n",
        "        label = int(df['Label'].iloc[i])  # 確保標籤為整數\n",
        "        filepath = os.path.join(save_dir, f\"{i}_label_{label}.png\")\n",
        "\n",
        "        # 繪製 K 線圖\n",
        "        fig, ax = plt.subplots(figsize=(6, 4))\n",
        "        ax.plot(window_data.index, window_data['Close'], label='Close', color='black', lw=2)\n",
        "        ax.plot(window_data.index, window_data['SMA_5'], label='SMA_5', color='blue', linestyle='--')\n",
        "        ax.plot(window_data.index, window_data['SMA_20'], label='SMA_20', color='red', linestyle='--')\n",
        "        ax.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(filepath)\n",
        "        plt.close(fig)\n",
        "\n",
        "generate_candlestick_images(df_stat, save_dir=\"./candlestick_images\", window_size=5)\n",
        "\n",
        "# 特徵縮放\n",
        "features = df_stat[['Close', 'SMA_5', 'SMA_20', 'RSI']].values\n",
        "labels = df_stat['Label'].values\n",
        "feature_scaler = MinMaxScaler()\n",
        "scaled_features = feature_scaler.fit_transform(features)\n",
        "\n",
        "# 構建序列數據\n",
        "N = 5  # 窗口大小\n",
        "X, y = [], []\n",
        "for i in range(N, len(scaled_features)):\n",
        "    X.append(scaled_features[i-N:i])\n",
        "    y.append(labels[i])\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# 分割數據集\n",
        "train_size = int(len(X) * 0.7)\n",
        "train_features, test_features = X[:train_size], X[train_size:]\n",
        "train_labels, test_labels = y[:train_size], y[train_size:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5bFZNRhhAPO",
        "outputId": "055cb380-7fd4-49cb-f7fd-8a9b8fb7cd63"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-7b609dfa3153>:8: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  label = int(df.iloc[i]['Label'])  # 確保標籤為整數\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 檢查缺失影像並補充\n",
        "def check_and_generate_missing_images(indices, features, labels, df, save_dir, window_size):\n",
        "    for idx in indices:\n",
        "        if idx < window_size or idx >= len(df):\n",
        "            continue  # 超出範圍的索引\n",
        "\n",
        "        # 確保影像存在\n",
        "        label = labels[idx - window_size]  # 測試數據的標籤\n",
        "        filepath = os.path.join(save_dir, f\"{idx}_label_{label}.png\")\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"Missing file detected, generating: {filepath}\")\n",
        "            window_data = df.iloc[idx-window_size:idx]\n",
        "            fig, ax = plt.subplots(figsize=(6, 4))\n",
        "            ax.plot(window_data.index, window_data['Close'], label='Close', color='black', lw=2)\n",
        "            ax.plot(window_data.index, window_data['SMA_5'], label='SMA_5', color='blue', linestyle='--')\n",
        "            ax.plot(window_data.index, window_data['SMA_20'], label='SMA_20', color='red', linestyle='--')\n",
        "            ax.legend()\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(filepath)\n",
        "            plt.close(fig)\n",
        "\n",
        "test_indices = list(range(len(test_features)))\n",
        "check_and_generate_missing_images(\n",
        "    indices=[idx + N for idx in test_indices],\n",
        "    features=test_features,\n",
        "    labels=test_labels,\n",
        "    df=df_stat,\n",
        "    save_dir=\"./candlestick_images\",\n",
        "    window_size=N\n",
        ")"
      ],
      "metadata": {
        "id": "PZ3m0hGvhClx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 自定義 Dataset\n",
        "class MultimodalStockDataset(Dataset):\n",
        "    def __init__(self, features, labels, image_dir, indices, transform=None):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "        self.image_dir = image_dir\n",
        "        self.indices = indices\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq_features = torch.tensor(self.features[self.indices[idx]], dtype=torch.float32)\n",
        "        label = int(self.labels[self.indices[idx]])  # 確保標籤為整數\n",
        "\n",
        "        # 加載對應的 K 線圖\n",
        "        image_path = os.path.join(self.image_dir, f\"{self.indices[idx]+N}_label_{label}.png\")\n",
        "        if not os.path.exists(image_path):\n",
        "            raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
        "\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, seq_features, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# 定義圖像變換\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# 構建 Dataset 和 DataLoader\n",
        "train_indices = list(range(len(train_features)))\n",
        "test_indices = list(range(len(test_features)))\n",
        "\n",
        "train_dataset = MultimodalStockDataset(train_features, train_labels, \"./candlestick_images\", train_indices, transform)\n",
        "test_dataset = MultimodalStockDataset(test_features, test_labels, \"./candlestick_images\", test_indices, transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "07Bkn4MIhFFB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義多模態模型\n",
        "class MultimodalModel(nn.Module):\n",
        "    def __init__(self, seq_input_dim, hidden_dim):\n",
        "        super(MultimodalModel, self).__init__()\n",
        "        self.cnn = models.resnet18(pretrained=True)\n",
        "        self.cnn.fc = nn.Linear(self.cnn.fc.in_features, 128)\n",
        "        self.rnn = nn.LSTM(input_size=seq_input_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "        self.fc_seq = nn.Linear(hidden_dim, 128)\n",
        "        self.fc_combined = nn.Linear(256, 2)  # 二分類\n",
        "\n",
        "    def forward(self, image, sequence_features):\n",
        "        image_features = self.cnn(image)\n",
        "        _, (hidden, _) = self.rnn(sequence_features)\n",
        "        seq_features = self.fc_seq(hidden[-1])\n",
        "        combined = torch.cat((image_features, seq_features), dim=1)\n",
        "        output = self.fc_combined(combined)\n",
        "        return output"
      ],
      "metadata": {
        "id": "PhNvnGpLhImx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化模型\n",
        "seq_input_dim = train_features.shape[2]\n",
        "hidden_dim = 32\n",
        "model = MultimodalModel(seq_input_dim, hidden_dim).to(device)\n",
        "\n",
        "# 訓練模型\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, seq_features, labels in train_loader:\n",
        "            images, seq_features, labels = images.to(device), seq_features.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images, seq_features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1TC6I5uhKvK",
        "outputId": "13dd5288-e085-452e-9a53-d61a9cb8473d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.1816\n",
            "Epoch [2/10], Loss: 0.1114\n",
            "Epoch [3/10], Loss: 0.0818\n",
            "Epoch [4/10], Loss: 0.0507\n",
            "Epoch [5/10], Loss: 0.0777\n",
            "Epoch [6/10], Loss: 0.0649\n",
            "Epoch [7/10], Loss: 0.0370\n",
            "Epoch [8/10], Loss: 0.0281\n",
            "Epoch [9/10], Loss: 0.0631\n",
            "Epoch [10/10], Loss: 0.0320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 模型評估並打印實際值與預測值 (只打印前五個)\n",
        "def evaluate_and_print_predictions(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, seq_features, labels in test_loader:\n",
        "            images, seq_features, labels = images.to(device), seq_features.to(device), labels.to(device)\n",
        "            outputs = model(images, seq_features)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # 打印前五個實際值與預測值\n",
        "    print(\"\\nReal Labels vs Predictions (Top 5):\")\n",
        "    for real, pred in zip(all_labels[:5], all_preds[:5]):\n",
        "        print(f\"Real: {real}, Predicted: {pred}\")\n",
        "\n",
        "    return accuracy, all_labels, all_preds\n",
        "\n",
        "# 執行模型評估\n",
        "accuracy, all_labels, all_preds = evaluate_and_print_predictions(model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwTs11473Qnm",
        "outputId": "97224163-d38a-4fb8-dc21-f5898dcfe50c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.6196\n",
            "\n",
            "Real Labels vs Predictions (Top 5):\n",
            "Real: 0, Predicted: 0\n",
            "Real: 0, Predicted: 0\n",
            "Real: 0, Predicted: 0\n",
            "Real: 0, Predicted: 0\n",
            "Real: 1, Predicted: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dy2tlMs960vD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}